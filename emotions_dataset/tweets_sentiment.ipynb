{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Students: Lin Yang, Mariia Isaieva, Martin Sejas <center>NLP Course <br><small>Graded Project Instructions <br>Spring 2023</small></center>\n",
    "\n",
    "About the dataset: \n",
    "\n",
    "List of tweet texts with emotion labels like joy, sadness, fear, anger... \n",
    "Dataset is split into train, test and validation sets for building the machine learning model. At first, you are \n",
    "given only train and test sets. The validation one will be given in the end of the project for you to check \n",
    "the final performance of your algorithm (to make sure there is no overfitting over the test data). \n",
    "You can work on this project on group of one, two or three students. This exercise is mandatory, not \n",
    "giving it back is equivalent to getting to lowest grade. \n",
    "Goal: \n",
    "\n",
    "• Train different kind of models able to classify each text according to the sentiment mainly present \n",
    "in it \n",
    "\n",
    "• Compare the results of your different models and try to analyze and explain the differences\n",
    "\n",
    "Train different classification models relying mainly on \n",
    "\n",
    "1. A Fully Connected Neural Network (see Course 2) 5 points \n",
    "\n",
    "2. A Recurrent Neural Network, based on LSTM or GRU (see Course 3) 5 points \n",
    "\n",
    "3. A fine-tuned Transformer Architecture from a pretrained model that can be found on sites \n",
    "like HuggingFace (see Course 4) 5 points \n",
    "\n",
    "4. Compare the different models to find the best approach and try to duplicate it on a “real life” \n",
    "text classification approach (this new “real life” dataset will be given to you soon) 5 points"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Preprocessing the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.metrics import Precision, Recall, AUC\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler, CallbackList, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is a tweets sentiment dataset, it's quite straightforward, there are only 2 columns, the tweet itself, and the sentiment attached to it. We have been provided a train set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentiment\n",
       "0                            i didnt feel humiliated   sadness\n",
       "1  i can go from feeling so hopeless to so damned...   sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong     anger\n",
       "3  i am ever feeling nostalgic about the fireplac...      love\n",
       "4                               i am feeling grouchy     anger"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./train.txt', header=None, delimiter=';')\n",
    "df_test = pd.read_csv('./test.txt', header=None, delimiter=';')\n",
    "df_train = df_train.rename(columns={0: 'tweet', 1: 'sentiment'})\n",
    "df_test = df_test.rename(columns={0: 'tweet', 1: 'sentiment'})\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading our dataset we can see the class (sentiment) distribution of our tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sentiment\n",
       " joy         5362\n",
       " sadness     4666\n",
       " anger       2159\n",
       " fear        1937\n",
       " love        1304\n",
       " surprise     572\n",
       " Name: count, dtype: int64,\n",
       " (16000, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['sentiment'].value_counts(), df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sentiment\n",
       " joy         695\n",
       " sadness     581\n",
       " anger       275\n",
       " fear        224\n",
       " love        159\n",
       " surprise     66\n",
       " Name: count, dtype: int64,\n",
       " (2000, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['sentiment'].value_counts(), df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that there are class inbalances. Especially regarding joy and surprise.\n",
    "\n",
    "We will also separate each tweet from it's label to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train = df_train['tweet']\n",
    "texts_test = df_test['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 0, ..., 2, 0, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(df_train['sentiment'])\n",
    "y_test = le.transform(df_test['sentiment'])\n",
    "y_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing the tweets (Lemmetizing) with the Spacy library."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmetization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to be using the famous [Spacy](https://spacy.io/) Library for tokenization, it's the best performing one in terms of computational cost and performance.\n",
    "\n",
    "We will be loading the english core *medium* dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have spacy working please make sure to run the following commands. \n",
    "\n",
    "```bash\n",
    "pip install spacy\n",
    "```\n",
    "\n",
    "Once the package has been installed, make sure to download the language model, in our case, *en-core-web-md* will be used, and can be downloaded by the following command. \n",
    "\n",
    "```bash \n",
    "python -m spacy download en_core_web_md\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "#Function to tokenize\n",
    "def preprocess_text(text):\n",
    "    #every tweet will become a document \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    #Creating a list of tokens by lemmatizing the words, filtering stop words.\n",
    "    tokens = [token.lemma_.lower().strip() for token in doc if not token.is_stop]\n",
    "    \n",
    "    #Join all the words in one sentence\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the *preprocess_text* function, we will pre-process the tweet text, and with that we can apply it to both of our dataframes as a new series, and see the output.\n",
    "\n",
    "*Warning this cell takes over 2 minutes to run!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>not feel humiliate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>feel hopeless damn hopeful care awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "      <td>m grab minute post feel greedy wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "      <td>feel nostalgic fireplace know property</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "      <td>feel grouchy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentiment  \\\n",
       "0                            i didnt feel humiliated   sadness   \n",
       "1  i can go from feeling so hopeless to so damned...   sadness   \n",
       "2   im grabbing a minute to post i feel greedy wrong     anger   \n",
       "3  i am ever feeling nostalgic about the fireplac...      love   \n",
       "4                               i am feeling grouchy     anger   \n",
       "\n",
       "                                processed  \n",
       "0                      not feel humiliate  \n",
       "1   feel hopeless damn hopeful care awake  \n",
       "2    m grab minute post feel greedy wrong  \n",
       "3  feel nostalgic fireplace know property  \n",
       "4                            feel grouchy  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['processed'] = df_train['tweet'].apply(preprocess_text)\n",
    "df_test['processed'] = df_test['tweet'].apply(preprocess_text)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1- Fully Connected Neural Network(5 Points)\n",
    "### TF-IDF embedding for Sequential Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using sklearn's TFidfVectorizer to be able to process the data and feed it into our Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 5587)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "\n",
    "dtm_train = tfidf.fit_transform(df_train['processed'])\n",
    "dtm_test = tfidf.transform(df_test['processed'])\n",
    "dtm_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the training set to training and validation sets for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ = dtm_train.toarray()\n",
    "X_test_ = dtm_test.toarray()\n",
    "y_train_ = y_train\n",
    "y_test_ = y_test\n",
    "# X_train_ = np.vstack((X_train_, X_test_))\n",
    "# y_train_ = np.concatenate((y_train, y_test))\n",
    "\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "\n",
    "\n",
    "# X_train_, X_test_, y_train, y_test_ = train_test_split(X_train_, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "X_train_, X_val_, y_train_, y_val_ = train_test_split(X_train_, y_train, test_size=0.2, random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the label in one hot encoding fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12800, 6), (2000, 6), (3200, 6))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_encoded = to_categorical(y_train_)\n",
    "y_test_encoded = to_categorical(y_test_)\n",
    "y_val_encoded = to_categorical(y_val_)\n",
    "y_train_encoded.shape, y_test_encoded.shape, y_val_encoded.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully connect NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the fully connected NN with tensorflow.\n",
    "\n",
    "The first layer has a high number of nerons because the input data set has `>5000` features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 4096)              22888448  \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 2048)              8390656   \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 64)                65600     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33443270 (127.58 MB)\n",
      "Trainable params: 33443270 (127.58 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4096, activation='selu', kernel_initializer='lecun_normal', input_shape=(X_train_.shape[1],), kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "model.add(Dense(2048, activation='selu', kernel_initializer='lecun_normal', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "model.add(Dense(1024, activation='selu', kernel_initializer='lecun_normal', kernel_regularizer=tf.keras.regularizers.l2(0.1)))\n",
    "# model.add(Dense(512, activation='selu', kernel_initializer='lecun_normal', ))\n",
    "# model.add(Dense(128, activation='selu', kernel_initializer='lecun_normal', ))\n",
    "model.add(Dense(64, activation='selu',))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.layers[-1].bias.assign(class_weights)\n",
    "model.compile(optimizer='Adam', loss=tf.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the early stopping condition and use a dynamic learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(step_decay)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=3) # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "50/50 [==============================] - 8s 162ms/step - loss: 26.8132 - accuracy: 0.5688 - val_loss: 10.9793 - val_accuracy: 0.6897 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 8s 167ms/step - loss: 5.2753 - accuracy: 0.7626 - val_loss: 2.5073 - val_accuracy: 0.8031 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 8s 166ms/step - loss: 1.7318 - accuracy: 0.8741 - val_loss: 1.5016 - val_accuracy: 0.8344 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 8s 162ms/step - loss: 1.1819 - accuracy: 0.8884 - val_loss: 1.1866 - val_accuracy: 0.8450 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 9s 182ms/step - loss: 0.9789 - accuracy: 0.8897 - val_loss: 1.0605 - val_accuracy: 0.8378 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 9s 185ms/step - loss: 0.8859 - accuracy: 0.8910 - val_loss: 1.0391 - val_accuracy: 0.8300 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 8s 163ms/step - loss: 0.8108 - accuracy: 0.8997 - val_loss: 0.9613 - val_accuracy: 0.8319 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 8s 160ms/step - loss: 0.8176 - accuracy: 0.8908 - val_loss: 1.0423 - val_accuracy: 0.8091 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 10s 192ms/step - loss: 0.7718 - accuracy: 0.8970 - val_loss: 0.9358 - val_accuracy: 0.8234 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 11s 224ms/step - loss: 0.6324 - accuracy: 0.9363 - val_loss: 0.8143 - val_accuracy: 0.8472 - lr: 5.0000e-04\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 10s 197ms/step - loss: 0.5732 - accuracy: 0.9509 - val_loss: 0.8084 - val_accuracy: 0.8438 - lr: 5.0000e-04\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 9s 173ms/step - loss: 0.5749 - accuracy: 0.9469 - val_loss: 0.8759 - val_accuracy: 0.8106 - lr: 5.0000e-04\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 9s 179ms/step - loss: 0.5735 - accuracy: 0.9458 - val_loss: 0.8024 - val_accuracy: 0.8422 - lr: 5.0000e-04\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 9s 182ms/step - loss: 0.5663 - accuracy: 0.9463 - val_loss: 0.8081 - val_accuracy: 0.8397 - lr: 5.0000e-04\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 9s 179ms/step - loss: 0.5547 - accuracy: 0.9484 - val_loss: 0.8254 - val_accuracy: 0.8331 - lr: 5.0000e-04\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 11s 212ms/step - loss: 0.5598 - accuracy: 0.9449 - val_loss: 0.8161 - val_accuracy: 0.8356 - lr: 5.0000e-04\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 10s 196ms/step - loss: 0.5484 - accuracy: 0.9481 - val_loss: 0.7995 - val_accuracy: 0.8406 - lr: 5.0000e-04\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 10s 207ms/step - loss: 0.5322 - accuracy: 0.9527 - val_loss: 0.7924 - val_accuracy: 0.8403 - lr: 5.0000e-04\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 9s 187ms/step - loss: 0.5372 - accuracy: 0.9493 - val_loss: 0.8208 - val_accuracy: 0.8359 - lr: 5.0000e-04\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 11s 214ms/step - loss: 0.5010 - accuracy: 0.9652 - val_loss: 0.7829 - val_accuracy: 0.8378 - lr: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_, y_train_encoded, validation_data=(X_val_, y_val_encoded), epochs=20, batch_size=256, callbacks=[early_stopping, lr_scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss, val_loss = history.history['loss'], history.history['val_loss']\n",
    "\n",
    "plt.plot(loss, label='loss')\n",
    "plt.plot(val_loss, label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 2s 25ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.75      0.81       275\n",
      "           1       0.85      0.79      0.82       224\n",
      "           2       0.83      0.92      0.87       695\n",
      "           3       0.71      0.65      0.68       159\n",
      "           4       0.86      0.89      0.87       581\n",
      "           5       0.76      0.48      0.59        66\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.81      0.75      0.77      2000\n",
      "weighted avg       0.84      0.84      0.83      2000\n",
      "\n",
      "[[206   8  12   6  42   1]\n",
      " [  9 177  12   0  21   5]\n",
      " [  4   4 639  29  15   4]\n",
      " [  1   1  45 104   8   0]\n",
      " [ 12   9  37   7 516   0]\n",
      " [  3  10  21   0   0  32]]\n",
      "0.837\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test_)\n",
    "prediction_labels = predictions.argmax(axis=1)\n",
    "print(classification_report(y_test, prediction_labels))\n",
    "print(confusion_matrix(y_test_, prediction_labels))\n",
    "print(accuracy_score(y_test_, prediction_labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have tried several dozens of times on this model: increasing and reducing the layers, increasing and reducing the neurons in each layer, tuning the regularization parameter, changing regularization, tuning the learning rate, batch size, *etc*.\n",
    "\n",
    "I also tried to experiment on the different input, using different representation of original text for model training, such as embedding with spacy. There were several different accuracy ceiling for my model from low to high with increasing the model complexity, `34%` to `56%`, and `86%`. And finally I got this result with the tf_idf matrix representation for training the model while the scale of the model is large with nearly 34 million. And the Accuracy on test was improved from `< 40%` to now `> 80%`.\n",
    "\n",
    "With `> 80%` accuracy, I also run dozens of experimentation to improve the accuracy, however, it is very hard to get a better accuracy, in the meantime I am already overfitting with the training set. I tried to tackle the overfitting problem, but I will get lower accuracy. So I decided to keep this model setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model, the folder of saved model is ignored for commit to github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: FNN_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: FNN_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('FNN_model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN, LSTM and GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(history):\n",
    "    hist_df = pd.DataFrame(history.history)\n",
    "    hist_df.columns=[\"loss\", \"accuracy\", \"val_loss\", \"val_accuracy\"]\n",
    "    hist_df.index = np.arange(1, len(hist_df)+1)\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=2, sharex=True, figsize=(16, 10))\n",
    "    axs[0].plot(hist_df.val_accuracy, lw=3, label='Validation Accuracy')\n",
    "    axs[0].plot(hist_df.accuracy, lw=3, label='Training Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].grid()\n",
    "    axs[0].legend(loc=0)\n",
    "    axs[1].plot(hist_df.val_loss, lw=3, label='Validation Loss')\n",
    "    axs[1].plot(hist_df.loss, lw=3, label='Training Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].grid()\n",
    "    axs[1].legend(loc=0)\n",
    "\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>not feel humiliate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>feel hopeless damn hopeful care awake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "      <td>m grab minute post feel greedy wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "      <td>feel nostalgic fireplace know property</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "      <td>feel grouchy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentiment  \\\n",
       "0                            i didnt feel humiliated   sadness   \n",
       "1  i can go from feeling so hopeless to so damned...   sadness   \n",
       "2   im grabbing a minute to post i feel greedy wrong     anger   \n",
       "3  i am ever feeling nostalgic about the fireplac...      love   \n",
       "4                               i am feeling grouchy     anger   \n",
       "\n",
       "                                processed  \n",
       "0                      not feel humiliate  \n",
       "1   feel hopeless damn hopeful care awake  \n",
       "2    m grab minute post feel greedy wrong  \n",
       "3  feel nostalgic fireplace know property  \n",
       "4                            feel grouchy  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_length = df_train['tweet'].map(lambda x: len(x)).sort_values().values[-1] # the length of the longest tweet 300\n",
    "max_length = 100\n",
    "trunc_type='post'\n",
    "# oov_tok = \"<OOV>\"\n",
    "\n",
    "tokenizer = Tokenizer() #(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(df_train['tweet'])\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(df_train['tweet'])\n",
    "padded = pad_sequences(sequences, maxlen=max_length, truncating=trunc_type)\n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(df_test['tweet'])\n",
    "testing_padded = pad_sequences(testing_sequences,maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(df_train['sentiment'])\n",
    "y_test = le.transform(df_test['sentiment'])\n",
    "y_train_encoded = to_categorical(y_train)\n",
    "y_test_encoded = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 100, 100)          1521300   \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 128)               84480     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 6)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1610106 (6.14 MB)\n",
      "Trainable params: 1610106 (6.14 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = max_length\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    Bidirectional(LSTM(64)), #32 \n",
    "    Dropout(0.4),\n",
    "    Dense(32, activation='leaky_relu', kernel_regularizer='l1_l2'),\n",
    "    Dropout(0.4),\n",
    "    Dense(6, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "loss_function = 'categorical_crossentropy'\n",
    "optimizer = 'adam'\n",
    "\n",
    "model.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy', Precision(), Recall(), AUC()])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 32s 76ms/step - loss: 2.4517 - accuracy: 0.3246 - precision_1: 0.4074 - recall_1: 8.5937e-04 - auc_1: 0.7077 - val_loss: 1.6222 - val_accuracy: 0.3262 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - val_auc_1: 0.7213\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 28s 70ms/step - loss: 1.4274 - accuracy: 0.3801 - precision_1: 0.5340 - recall_1: 0.0988 - auc_1: 0.8078 - val_loss: 1.2881 - val_accuracy: 0.4272 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - val_auc_1: 0.8497\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 27s 66ms/step - loss: 1.2253 - accuracy: 0.4298 - precision_1: 0.5394 - recall_1: 0.2070 - auc_1: 0.8606 - val_loss: 1.2335 - val_accuracy: 0.4284 - val_precision_1: 0.5097 - val_recall_1: 0.2459 - val_auc_1: 0.8579\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 29s 73ms/step - loss: 1.1390 - accuracy: 0.4620 - precision_1: 0.5398 - recall_1: 0.2554 - auc_1: 0.8769 - val_loss: 1.1757 - val_accuracy: 0.4666 - val_precision_1: 0.5103 - val_recall_1: 0.2547 - val_auc_1: 0.8690\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 32s 81ms/step - loss: 1.0278 - accuracy: 0.5120 - precision_1: 0.5466 - recall_1: 0.3318 - auc_1: 0.8947 - val_loss: 1.1125 - val_accuracy: 0.4863 - val_precision_1: 0.5587 - val_recall_1: 0.1369 - val_auc_1: 0.8817\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 25s 63ms/step - loss: 0.9486 - accuracy: 0.5341 - precision_1: 0.5512 - recall_1: 0.3899 - auc_1: 0.9026 - val_loss: 1.0521 - val_accuracy: 0.5016 - val_precision_1: 0.5263 - val_recall_1: 0.2997 - val_auc_1: 0.8894\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 25s 62ms/step - loss: 0.8946 - accuracy: 0.5463 - precision_1: 0.5605 - recall_1: 0.4348 - auc_1: 0.9088 - val_loss: 1.0406 - val_accuracy: 0.5053 - val_precision_1: 0.5242 - val_recall_1: 0.3919 - val_auc_1: 0.8910\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 27s 67ms/step - loss: 0.8617 - accuracy: 0.5548 - precision_1: 0.5668 - recall_1: 0.4464 - auc_1: 0.9123 - val_loss: 1.0259 - val_accuracy: 0.5103 - val_precision_1: 0.5276 - val_recall_1: 0.3706 - val_auc_1: 0.8935\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 37s 93ms/step - loss: 0.7431 - accuracy: 0.6916 - precision_1: 0.7296 - recall_1: 0.6068 - auc_1: 0.9533 - val_loss: 0.7457 - val_accuracy: 0.7763 - val_precision_1: 0.8185 - val_recall_1: 0.7369 - val_auc_1: 0.9611\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 28s 69ms/step - loss: 0.4923 - accuracy: 0.8850 - precision_1: 0.9091 - recall_1: 0.8473 - auc_1: 0.9883 - val_loss: 0.6647 - val_accuracy: 0.8641 - val_precision_1: 0.8918 - val_recall_1: 0.8500 - val_auc_1: 0.9734\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 27s 68ms/step - loss: 0.3759 - accuracy: 0.9347 - precision_1: 0.9494 - recall_1: 0.9177 - auc_1: 0.9945 - val_loss: 0.5783 - val_accuracy: 0.8869 - val_precision_1: 0.9005 - val_recall_1: 0.8684 - val_auc_1: 0.9758\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 28s 71ms/step - loss: 0.3100 - accuracy: 0.9551 - precision_1: 0.9659 - recall_1: 0.9416 - auc_1: 0.9971 - val_loss: 0.5511 - val_accuracy: 0.8922 - val_precision_1: 0.9070 - val_recall_1: 0.8684 - val_auc_1: 0.9778\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 26s 64ms/step - loss: 0.2853 - accuracy: 0.9632 - precision_1: 0.9708 - recall_1: 0.9516 - auc_1: 0.9975 - val_loss: 0.5539 - val_accuracy: 0.8950 - val_precision_1: 0.9032 - val_recall_1: 0.8831 - val_auc_1: 0.9775\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 31s 79ms/step - loss: 0.2609 - accuracy: 0.9694 - precision_1: 0.9747 - recall_1: 0.9616 - auc_1: 0.9979 - val_loss: 0.5222 - val_accuracy: 0.8984 - val_precision_1: 0.9078 - val_recall_1: 0.8919 - val_auc_1: 0.9794\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 28s 69ms/step - loss: 0.2422 - accuracy: 0.9723 - precision_1: 0.9768 - recall_1: 0.9659 - auc_1: 0.9983 - val_loss: 0.5398 - val_accuracy: 0.8934 - val_precision_1: 0.9031 - val_recall_1: 0.8878 - val_auc_1: 0.9777\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 33s 82ms/step - loss: 0.2737 - accuracy: 0.9656 - precision_1: 0.9709 - recall_1: 0.9594 - auc_1: 0.9972 - val_loss: 0.5300 - val_accuracy: 0.8909 - val_precision_1: 0.9028 - val_recall_1: 0.8856 - val_auc_1: 0.9797\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 33s 83ms/step - loss: 0.2105 - accuracy: 0.9792 - precision_1: 0.9824 - recall_1: 0.9746 - auc_1: 0.9990 - val_loss: 0.5209 - val_accuracy: 0.8984 - val_precision_1: 0.9055 - val_recall_1: 0.8953 - val_auc_1: 0.9791\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 29s 72ms/step - loss: 0.1944 - accuracy: 0.9827 - precision_1: 0.9852 - recall_1: 0.9798 - auc_1: 0.9992 - val_loss: 0.5223 - val_accuracy: 0.8991 - val_precision_1: 0.9044 - val_recall_1: 0.8959 - val_auc_1: 0.9792\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 28s 70ms/step - loss: 0.1799 - accuracy: 0.9861 - precision_1: 0.9888 - recall_1: 0.9832 - auc_1: 0.9996 - val_loss: 0.5374 - val_accuracy: 0.9006 - val_precision_1: 0.9053 - val_recall_1: 0.8994 - val_auc_1: 0.9763\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 26s 66ms/step - loss: 0.1958 - accuracy: 0.9827 - precision_1: 0.9857 - recall_1: 0.9803 - auc_1: 0.9988 - val_loss: 0.5470 - val_accuracy: 0.8856 - val_precision_1: 0.8938 - val_recall_1: 0.8813 - val_auc_1: 0.9760\n"
     ]
    }
   ],
   "source": [
    "predictors = np.array(padded) \n",
    "label = np.array(y_train_encoded)\n",
    "epochs_value = 50\n",
    "validation_split_value = 0.2\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=3)\n",
    "\n",
    "history = model.fit(predictors, label, epochs=epochs_value, verbose=1, validation_split=validation_split_value, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss, val_loss = history.history['loss'], history.history['val_loss']\n",
    "plt.plot(loss, label='loss')\n",
    "plt.plot(val_loss, label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 2s 16ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89       275\n",
      "           1       0.84      0.91      0.87       224\n",
      "           2       0.95      0.88      0.91       695\n",
      "           3       0.82      0.79      0.80       159\n",
      "           4       0.87      0.96      0.91       581\n",
      "           5       0.77      0.67      0.72        66\n",
      "\n",
      "    accuracy                           0.89      2000\n",
      "   macro avg       0.86      0.85      0.85      2000\n",
      "weighted avg       0.89      0.89      0.89      2000\n",
      "\n",
      "[[239  11   4   0  21   0]\n",
      " [  7 204   0   0   5   8]\n",
      " [  0   3 613  27  47   5]\n",
      " [  1   3  25 125   5   0]\n",
      " [ 14   5   5   0 557   0]\n",
      " [  0  18   1   1   2  44]]\n",
      "0.891\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(testing_padded)\n",
    "prediction_labels = predictions.argmax(axis=1)\n",
    "print(classification_report(y_test, prediction_labels))\n",
    "print(confusion_matrix(y_test, prediction_labels))\n",
    "print(accuracy_score(y_test, prediction_labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer based Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentiment\n",
       "0                            i didnt feel humiliated   sadness\n",
       "1  i can go from feeling so hopeless to so damned...   sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong     anger\n",
       "3  i am ever feeling nostalgic about the fireplac...      love\n",
       "4                               i am feeling grouchy     anger"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_train = df_train['tweet']\n",
    "texts_test = df_test['tweet']\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importing Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fast Encode Function Retrieved From the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def fast_encode(texts, tokenizer, chunk_size=256, maxlen=512):\n",
    "    \"\"\"\n",
    "    Encoder for encoding the text into sequence of integers for BERT Input\n",
    "    \"\"\"\n",
    "    tokenizer.enable_truncation(max_length=maxlen)\n",
    "    tokenizer.enable_padding(length=maxlen)\n",
    "    all_ids = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), chunk_size)):\n",
    "        text_chunk = texts[i:i+chunk_size].tolist()\n",
    "        encs = tokenizer.encode_batch(text_chunk)\n",
    "        all_ids.extend([enc.ids for enc in encs])\n",
    "    \n",
    "    return np.array(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizer(vocabulary_size=119547, model=BertWordPiece, unk_token=[UNK], sep_token=[SEP], cls_token=[CLS], pad_token=[PAD], mask_token=[MASK], clean_text=True, handle_chinese_chars=True, strip_accents=None, lowercase=False, wordpieces_prefix=##)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "\n",
    "#Loading bert tokenizer\n",
    "bert_tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased')\n",
    "\n",
    "#Saving it on our local folder\n",
    "bert_tokenizer.save_pretrained('.')\n",
    "\n",
    "\n",
    "#Loading a fast tokenizer\n",
    "fast_tokenizer = BertWordPieceTokenizer('vocab.txt', lowercase=False)\n",
    "fast_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_X_train, bert_X_valid, bert_Y_train, bert_Y_valid = train_test_split(df_train['tweet'].values, df_train['sentiment'].values,test_size=0.2,random_state=42,stratify=df_train['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding raw test for training validation and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 98.03it/s] \n",
      "100%|██████████| 13/13 [00:00<00:00, 172.87it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 180.64it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = fast_encode(bert_X_train, fast_tokenizer, maxlen=max_length)\n",
    "X_valid = fast_encode(bert_X_valid, fast_tokenizer, maxlen=max_length)\n",
    "X_test = fast_encode(df_test['tweet'].to_numpy(), fast_tokenizer, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12800, 100)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(bert_Y_train)\n",
    "y_valid = le.transform(bert_Y_valid)\n",
    "y_test = le.transform(df_test['sentiment'])\n",
    "y_train_encoded = to_categorical(y_train)\n",
    "y_valid_encoded = to_categorical(y_valid)\n",
    "y_test_encoded = to_categorical(y_test)\n",
    "\n",
    "\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((X_train, y_train_encoded))\n",
    "    .repeat()\n",
    "    .shuffle(2048)\n",
    "    .batch(BATCH_SIZE)\n",
    "    \n",
    ")\n",
    "\n",
    "valid_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((X_valid, y_valid_encoded))\n",
    "    .batch(BATCH_SIZE)\n",
    "    .cache()\n",
    "    \n",
    ")\n",
    "\n",
    "test_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices(X_test,y_test_encoded)\n",
    "    .batch(BATCH_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating TensorFlow Datasets with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((X_train, y_train_encoded))\n",
    "    .repeat()\n",
    "    .shuffle(2048)\n",
    "    .batch(BATCH_SIZE)\n",
    "    \n",
    ")\n",
    "\n",
    "valid_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((X_valid, y_valid_encoded))\n",
    "    .batch(BATCH_SIZE)\n",
    "    .cache()\n",
    "    \n",
    ")\n",
    "\n",
    "test_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((X_test,y_test_encoded))\n",
    "    .batch(BATCH_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers.experimental import Adam\n",
    "\n",
    "def build_model(transformer, max_len=512):\n",
    "    \"\"\"\n",
    "    function for training the BERT model\n",
    "    \"\"\"\n",
    "    input_word_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    sequence_output = transformer(input_word_ids)[0]\n",
    "    cls_token = sequence_output[:, 0, :]\n",
    "    out = Dense(6, activation='softmax')(cls_token)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_word_ids, outputs=out)\n",
    "    model.compile(Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy', Precision(), Recall(), AUC()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading model.safetensors: 100%|██████████| 542M/542M [00:39<00:00, 13.9MB/s] \n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m transformer_layer \u001b[39m=\u001b[39m (\n\u001b[0;32m      2\u001b[0m     transformers\u001b[39m.\u001b[39mTFDistilBertModel\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m'\u001b[39m\u001b[39mdistilbert-base-multilingual-cased\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m )\n\u001b[0;32m      6\u001b[0m bert_model \u001b[39m=\u001b[39m build_model(transformer_layer, max_len\u001b[39m=\u001b[39mmax_length)\n\u001b[1;32m----> 7\u001b[0m model\u001b[39m.\u001b[39msummary()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "transformer_layer = (\n",
    "    transformers.TFDistilBertModel.from_pretrained('distilbert-base-multilingual-cased')\n",
    ")\n",
    "\n",
    "\n",
    "bert_model = build_model(transformer_layer, max_len=max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_word_ids (InputLayer  [(None, 100)]             0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " tf_distil_bert_model (TFDi  TFBaseModelOutput(last_   134734080 \n",
      " stilBertModel)              hidden_state=(None, 100             \n",
      "                             , 768),                             \n",
      "                              hidden_states=None, at             \n",
      "                             tentions=None)                      \n",
      "                                                                 \n",
      " tf.__operators__.getitem (  (None, 768)               0         \n",
      " SlicingOpLambda)                                                \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 4614      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134738694 (513.99 MB)\n",
      "Trainable params: 134738694 (513.99 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freezing all other layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model.layers[0].trainable = False\n",
    "bert_model.layers[1].trainable = False\n",
    "bert_model.layers[2].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_word_ids (InputLayer  [(None, 100)]             0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " tf_distil_bert_model (TFDi  TFBaseModelOutput(last_   134734080 \n",
      " stilBertModel)              hidden_state=(None, 100             \n",
      "                             , 768),                             \n",
      "                              hidden_states=None, at             \n",
      "                             tentions=None)                      \n",
      "                                                                 \n",
      " tf.__operators__.getitem (  (None, 768)               0         \n",
      " SlicingOpLambda)                                                \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 4614      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134738694 (513.99 MB)\n",
      "Trainable params: 4614 (18.02 KB)\n",
      "Non-trainable params: 134734080 (513.97 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 18/800 [..............................] - ETA: 39:02 - loss: 3.5536 - accuracy: 0.2500 - precision: 0.2333 - recall: 0.1701 - auc: 0.5437"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m n_steps \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m BATCH_SIZE\n\u001b[1;32m----> 2\u001b[0m train_history \u001b[39m=\u001b[39m bert_model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      3\u001b[0m     train_dataset,\n\u001b[0;32m      4\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49mn_steps,\n\u001b[0;32m      5\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalid_dataset,\n\u001b[0;32m      6\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m\n\u001b[0;32m      7\u001b[0m )\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\computer-vision\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\computer-vision\\Lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\computer-vision\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\computer-vision\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\computer-vision\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\computer-vision\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\computer-vision\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\computer-vision\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\computer-vision\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1463\u001b[0m   )\n\u001b[0;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\computer-vision\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_steps = X_train.shape[0] // BATCH_SIZE\n",
    "train_history = bert_model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=n_steps,\n",
    "    validation_data=valid_dataset,\n",
    "    epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with real case data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully connected NNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the real case data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r_train = pd.read_csv('./real_case_data/train.csv')\n",
    "df_r_test = pd.read_csv('./real_case_data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r_train['processed'] = df_r_train['article_title'].apply(preprocess_text)\n",
    "df_r_test['processed'] = df_r_test['article_title'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFIDF transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stopwords_list = stopwords.words('english') + stopwords.words('french')\n",
    "\n",
    "tfidf = TfidfVectorizer(max_df=0.95, min_df=2, stop_words=final_stopwords_list)\n",
    "\n",
    "dtm_r_train = tfidf.fit_transform(df_r_train['processed'])\n",
    "dtm_r_test = tfidf.transform(df_r_test['processed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the training and test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_r_train = dtm_r_train.toarray()\n",
    "y_r_train = df_r_train['is_ecology']\n",
    "\n",
    "X_r_test = dtm_r_test.toarray()\n",
    "y_r_test = df_r_test['is_ecology']\n",
    "\n",
    "y_r_train_encoded = to_categorical(y_r_train)\n",
    "y_r_test_encoded = to_categorical(y_r_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the train and validation data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weights = compute_class_weight('balanced', classes=np.unique(y_r_train), y=y_r_train)\n",
    "X_r_train, X_r_val, y_r_train_encoded, y_r_val_encoded = train_test_split(X_r_train, y_r_train_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model with same architecture, but change the last output layer as we have two categories in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_25 (Dense)            (None, 2048)              5011456   \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7782338 (29.69 MB)\n",
      "Trainable params: 7782338 (29.69 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2048, activation='selu', kernel_initializer='lecun_normal', input_shape=(X_r_train.shape[1],), kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "model.add(Dense(1024, activation='selu', kernel_initializer='lecun_normal', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "model.add(Dense(512, activation='selu', kernel_initializer='lecun_normal', kernel_regularizer=tf.keras.regularizers.l2(0.1)))\n",
    "model.add(Dense(256, activation='selu', kernel_initializer='lecun_normal', ))\n",
    "# model.add(Dense(128, activation='selu', kernel_initializer='lecun_normal', ))\n",
    "model.add(Dense(64, activation='selu', kernel_initializer='lecun_normal',))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='Adam', loss=tf.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up early stopping and dynamic learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(step_decay)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=3) # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "7/7 [==============================] - 3s 253ms/step - loss: 69.3208 - accuracy: 0.8691 - val_loss: 53.2036 - val_accuracy: 0.9887 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 43.9753 - accuracy: 0.9746 - val_loss: 33.0106 - val_accuracy: 0.9887 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 26.9942 - accuracy: 0.9893 - val_loss: 20.0201 - val_accuracy: 0.9887 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 16.2501 - accuracy: 0.9983 - val_loss: 11.9677 - val_accuracy: 0.9887 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 9.6581 - accuracy: 1.0000 - val_loss: 7.0818 - val_accuracy: 0.9887 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 5.6883 - accuracy: 0.9994 - val_loss: 4.1746 - val_accuracy: 0.9887 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 3.3272 - accuracy: 0.9989 - val_loss: 2.4494 - val_accuracy: 0.9887 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "7/7 [==============================] - 0s 72ms/step - loss: 1.9330 - accuracy: 0.9977 - val_loss: 1.4405 - val_accuracy: 0.9887 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 1.1183 - accuracy: 0.9983 - val_loss: 0.8516 - val_accuracy: 0.9887 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "7/7 [==============================] - 0s 72ms/step - loss: 0.7158 - accuracy: 0.9989 - val_loss: 0.6719 - val_accuracy: 0.9819 - lr: 5.0000e-04\n",
      "Epoch 11/15\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 0.5495 - accuracy: 0.9989 - val_loss: 0.5175 - val_accuracy: 0.9887 - lr: 5.0000e-04\n",
      "Epoch 12/15\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 0.4227 - accuracy: 0.9983 - val_loss: 0.4073 - val_accuracy: 0.9910 - lr: 5.0000e-04\n",
      "Epoch 13/15\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 0.3254 - accuracy: 1.0000 - val_loss: 0.3316 - val_accuracy: 0.9887 - lr: 5.0000e-04\n",
      "Epoch 14/15\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 0.2527 - accuracy: 1.0000 - val_loss: 0.2678 - val_accuracy: 0.9887 - lr: 5.0000e-04\n",
      "Epoch 15/15\n",
      "7/7 [==============================] - 1s 78ms/step - loss: 0.1973 - accuracy: 1.0000 - val_loss: 0.2193 - val_accuracy: 0.9887 - lr: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_r_train, y_r_train_encoded, validation_data=(X_r_val, y_r_val_encoded), epochs=15, batch_size=256, callbacks=[early_stopping, lr_scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 26ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91       241\n",
      "           1       0.78      0.13      0.23        53\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.81      0.56      0.57       294\n",
      "weighted avg       0.83      0.84      0.79       294\n",
      "\n",
      "[[239   2]\n",
      " [ 46   7]]\n",
      "0.8367346938775511\n"
     ]
    }
   ],
   "source": [
    "predictions_r = model.predict(X_r_test)\n",
    "prediction_labels_r = predictions_r.argmax(axis=1)\n",
    "print(classification_report(y_r_test, prediction_labels_r))\n",
    "print(confusion_matrix(y_r_test, prediction_labels_r))\n",
    "print(accuracy_score(y_r_test, prediction_labels_r))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models:\n",
    "`my_model = tf.keras.models.load_model('my_model')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
